{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae23e534-af74-4cbf-94f7-6217eb976548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 必要库\n",
    "%pip -q install geopandas shapely pyproj mapclassify contextily\n",
    "\n",
    "import os, warnings, numpy as np, pandas as pd, geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import mapclassify as mc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 输出目录\n",
    "OUT_DIR  = \"_gis_maps\";  os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 你的文件（同目录）\n",
    "GEOJSON_PATH = \"Ethiopia_AdminBoundaries.geojson\"  # Kebele 级多边形（你已提供）\n",
    "NDVI_CSV     = \"ETH_AwashKesem_NDVImean_byKebele_2018_2024_v01.csv\"\n",
    "UNITS_CSV    = \"ETH_AwashKesem_KebeleUnits_TreatControl_v01.csv\"  # treated / share\n",
    "RAIN_CSV     = \"ETH_AwashKesem_RAINJJASmean_byKebele_2018_2024_v01.csv\"  # 备选\n",
    "\n",
    "# 研究区（与 GEE 一致），EPSG:4326\n",
    "AOI = box(39.5, 8.6, 41.2, 10.9)\n",
    "\n",
    "# 你论文里的前/后两年\n",
    "YEAR0, YEAR1 = 2019, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9e69048-1cc3-4f48-80a2-20ffd93b949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON rows: 15670 columns: ['OBJECTID', 'R_NAME', 'R_CODE', 'Z_NAME', 'Z_CODE', 'W_NAME', 'W_CODE', 'RK_NAME', 'RK_CODE', 'COUNT', 'T_NAME', 'T_CODE'] ...\n",
      "Kebele in AOI: 883\n",
      "Name-like columns: ['R_NAME', 'Z_NAME', 'W_NAME', 'RK_NAME', 'T_NAME', 'UK_NAME', 'KK_NAME']\n"
     ]
    }
   ],
   "source": [
    "# 读 GeoJSON\n",
    "g_all = gpd.read_file(GEOJSON_PATH)\n",
    "print(\"GeoJSON rows:\", len(g_all), \"columns:\", list(g_all.columns)[:12], \"...\")\n",
    "\n",
    "# 找到能当 Kebele_ID 的列（按你在 GEE 脚本里的优先顺序）\n",
    "cand_id = None\n",
    "for c in [\"Kebele_ID\",\"GlobalID\",\"KK_CODE\",\"W_CODE\",\"ID\",\"id\",\"globalid\"]:\n",
    "    if c in g_all.columns:\n",
    "        cand_id = c; break\n",
    "if not cand_id:\n",
    "    raise ValueError(f\"GeoJSON 里找不到 Kebele 唯一标识列（Kebele_ID/GlobalID/KK_CODE 等）；实际列：{list(g_all.columns)}\")\n",
    "\n",
    "g_all[\"Kebele_ID\"] = g_all[cand_id].astype(str).str.strip()\n",
    "\n",
    "# 统一到 WGS84\n",
    "if g_all.crs is None:\n",
    "    g_all.set_crs(epsg=4326, inplace=True)\n",
    "else:\n",
    "    g_all = g_all.to_crs(epsg=4326)\n",
    "\n",
    "# 只保留 Awash Kesem AOI 范围内的 Kebele\n",
    "g = g_all[g_all.intersects(AOI)].copy()\n",
    "print(\"Kebele in AOI:\", len(g))\n",
    "assert len(g) > 0, \"AOI 内没有 Kebele 多边形；请检查 GeoJSON 是否全国覆盖/坐标系是否 WGS84\"\n",
    "\n",
    "# 可选：保留一些行政名列备用（不同数据源命名可能不一致）\n",
    "keep_name_cols = [c for c in g.columns if any(k in c.upper() for k in [\"W_NAME\",\"Z_NAME\",\"T_NAME\",\"NAME\"])]\n",
    "print(\"Name-like columns:\", keep_name_cols[:8])\n",
    "\n",
    "# 设定绘图坐标系（Web 墨卡托），便于底图（若联网可用）\n",
    "g_3857 = g.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c0b357e-38ad-4cbf-88c7-b5514d0166b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI CSV cols: ['Kebele_ID', 'Kebele_Name', 'W_NAME', 'Z_NAME', 'T_NAME', 'treated', 'treat_share', 'area_km2', 'Year', 'NDVI']  ... rows: 6090\n",
      "Units CSV merged cols: ['Kebele_ID', 'treated', 'treat_share', 'area_km2']\n",
      "合并后： 6103  NDVI 非缺失占比： 0.0\n",
      "Year 范围： 2018 → 2024\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "⚠️ 通过 Kebele_ID 并没有对上任何 NDVI。请核对：GeoJSON 里的 Kebele_ID 与 NDVI CSV 的 Kebele_ID 是否来自同一套源（GEE 里我们用 GlobalID/KK_CODE/W_CODE 之一）。",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 诊断：如果一条都没对上，直接报错（过去你遇到的那类问题）\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m g_ndvi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnotna()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ 通过 Kebele_ID 并没有对上任何 NDVI。请核对：GeoJSON 里的 Kebele_ID 与 NDVI CSV 的 Kebele_ID 是否来自同一套源（GEE 里我们用 GlobalID/KK_CODE/W_CODE 之一）。\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ⚠️ 通过 Kebele_ID 并没有对上任何 NDVI。请核对：GeoJSON 里的 Kebele_ID 与 NDVI CSV 的 Kebele_ID 是否来自同一套源（GEE 里我们用 GlobalID/KK_CODE/W_CODE 之一）。"
     ]
    }
   ],
   "source": [
    "# 读 NDVI 表\n",
    "ndvi = pd.read_csv(NDVI_CSV)\n",
    "print(\"NDVI CSV cols:\", list(ndvi.columns)[:12], \" ... rows:\", len(ndvi))\n",
    "\n",
    "# 标准化 Kebele_ID 与年份/数值列\n",
    "id_col = \"Kebele_ID\" if \"Kebele_ID\" in ndvi.columns else next(\n",
    "    c for c in ndvi.columns if c.lower() in [\"kebeleid\",\"globalid\",\"kk_code\",\"w_code\",\"id\",\"unit_id\"]\n",
    ")\n",
    "ndvi[\"Kebele_ID\"] = ndvi[id_col].astype(str).str.strip()\n",
    "ndvi[\"Year\"]      = pd.to_numeric(ndvi[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "ndvi[\"NDVI\"]      = pd.to_numeric(ndvi[\"NDVI\"], errors=\"coerce\")\n",
    "\n",
    "# 读 treated / treat_share（如果有）\n",
    "treated_df = None\n",
    "if os.path.exists(UNITS_CSV):\n",
    "    u = pd.read_csv(UNITS_CSV)\n",
    "    # 容错找到 ID 列\n",
    "    uid = \"Kebele_ID\" if \"Kebele_ID\" in u.columns else next(\n",
    "        c for c in u.columns if c.lower() in [\"kebeleid\",\"globalid\",\"kk_code\",\"w_code\",\"id\",\"unit_id\"]\n",
    "    )\n",
    "    u[\"Kebele_ID\"] = u[uid].astype(str).str.strip()\n",
    "    for c in [\"treated\",\"treat_share\",\"area_km2\"]:\n",
    "        if c in u.columns: u[c] = pd.to_numeric(u[c], errors=\"coerce\")\n",
    "    treated_df = u[[\"Kebele_ID\"] + [c for c in [\"treated\",\"treat_share\",\"area_km2\"] if c in u.columns]].drop_duplicates(\"Kebele_ID\")\n",
    "    print(\"Units CSV merged cols:\", list(treated_df.columns))\n",
    "\n",
    "# —— 合并 ——（以 Geo 为主，保证每个多边形一行）\n",
    "g_ndvi = g.merge(ndvi, on=\"Kebele_ID\", how=\"left\")\n",
    "if treated_df is not None:\n",
    "    g_ndvi = g_ndvi.merge(treated_df, on=\"Kebele_ID\", how=\"left\")\n",
    "\n",
    "print(\"合并后：\", len(g_ndvi), \" NDVI 非缺失占比：\", (1 - g_ndvi[\"NDVI\"].isna().mean()).round(3))\n",
    "print(\"Year 范围：\", g_ndvi[\"Year\"].min(), \"→\", g_ndvi[\"Year\"].max())\n",
    "\n",
    "# 诊断：如果一条都没对上，直接报错（过去你遇到的那类问题）\n",
    "if g_ndvi[\"NDVI\"].notna().sum() == 0:\n",
    "    raise RuntimeError(\"⚠️ 通过 Kebele_ID 并没有对上任何 NDVI。请核对：GeoJSON 里的 Kebele_ID 与 NDVI CSV 的 Kebele_ID 是否来自同一套源（GEE 里我们用 GlobalID/KK_CODE/W_CODE 之一）。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "411326f7-b4eb-4d53-a072-4efa74c63e05",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'NDVI_2024'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NDVI_2024'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m g_plot \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mmerge(pv, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKebele_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m g_plot\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{YEAR0: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, YEAR1: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m g_plot[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI_change\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mg_plot\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNDVI_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mYEAR1\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m g_plot[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(g_plot[[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYEAR1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNDVI_change\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 防止全部缺失导致色阶无范围\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/geopandas/geodataframe.py:1750\u001b[0m, in \u001b[0;36mGeoDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;124;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;124;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[1;32m   1748\u001b[0m \u001b[38;5;124;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1750\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1754\u001b[0m         pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_scalar(key)\n\u001b[1;32m   1755\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1758\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[1;32m   1759\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'NDVI_2024'"
     ]
    }
   ],
   "source": [
    "# 只取 2019 / 2024 两年\n",
    "sub = g_ndvi[g_ndvi[\"Year\"].isin([YEAR0, YEAR1])][[\"Kebele_ID\",\"Year\",\"NDVI\"]].dropna().copy()\n",
    "pv  = sub.pivot_table(index=\"Kebele_ID\", columns=\"Year\", values=\"NDVI\", aggfunc=\"mean\")\n",
    "\n",
    "# 回填到空间表\n",
    "g_plot = g.merge(pv, on=\"Kebele_ID\", how=\"left\")\n",
    "g_plot.rename(columns={YEAR0: f\"NDVI_{YEAR0}\", YEAR1: f\"NDVI_{YEAR1}\"}, inplace=True)\n",
    "g_plot[\"NDVI_change\"] = g_plot[f\"NDVI_{YEAR1}\"] - g_plot[f\"NDVI_{YEAR0}\"]\n",
    "\n",
    "print(g_plot[[f\"NDVI_{YEAR0}\", f\"NDVI_{YEAR1}\", \"NDVI_change\"]].describe().round(4))\n",
    "\n",
    "# 防止全部缺失导致色阶无范围\n",
    "for col in [f\"NDVI_{YEAR0}\", f\"NDVI_{YEAR1}\", \"NDVI_change\"]:\n",
    "    if g_plot[col].notna().sum() == 0:\n",
    "        g_plot[col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91a05535-f03d-4e42-ab8d-6e51f9e81d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_choropleth(gdf, column, title, cmap=\"YlGn\", qk=7, vmin=None, vmax=None, fname=None):\n",
    "    \"\"\"\n",
    "    gdf: GeoDataFrame（EPSG:4326 或 EPSG:3857 都可）\n",
    "    column: 填色字段\n",
    "    qk: 使用分位数分级（7 组），更稳健\n",
    "    \"\"\"\n",
    "    # 用 Web Mercator 画图（contextily 要求）\n",
    "    g3857 = gdf.to_crs(epsg=3857)\n",
    "\n",
    "    # 计算分级\n",
    "    vals = g3857[column].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(vals) == 0:\n",
    "        # 没有数据也画空轮廓，避免“空白”\n",
    "        fig, ax = plt.subplots(1,1,figsize=(7.5,7.2))\n",
    "        g3857.boundary.plot(ax=ax, color=\"#cccccc\", linewidth=0.3)\n",
    "        ax.set_axis_off(); ax.set_title(f\"{title}\\n(no data)\", fontsize=14)\n",
    "        if fname: plt.savefig(os.path.join(OUT_DIR, fname), dpi=260, bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    scheme = mc.Quantiles(vals, k=qk)\n",
    "    vmin = vals.min() if vmin is None else vmin\n",
    "    vmax = vals.max() if vmax is None else vmax\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize=(7.8,7.5))\n",
    "    g3857.plot(column=column, ax=ax, scheme=scheme, cmap=cmap, linewidth=0.1, edgecolor=\"#f5f5f5\")\n",
    "    g3857.boundary.plot(ax=ax, color=\"white\", linewidth=0.2, alpha=0.6)\n",
    "\n",
    "    # 可选底图（若没网，不影响制图）\n",
    "    try:\n",
    "        import contextily as cx\n",
    "        cx.add_basemap(ax, crs=g3857.crs.to_string(), attribution=\"\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 颜色条\n",
    "    sm = mpl.cm.ScalarMappable(cmap=cmap, norm=mpl.colors.Normalize(vmin=vmin, vmax=vmax))\n",
    "    cbar = plt.colorbar(sm, ax=ax, fraction=0.025, pad=0.01)\n",
    "    cbar.ax.tick_params(labelsize=9)\n",
    "\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    if fname: plt.savefig(os.path.join(OUT_DIR, fname), dpi=260, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf6b6dd7-8408-4a06-9171-1233df12d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON columns: Index(['OBJECTID', 'R_NAME', 'R_CODE', 'Z_NAME', 'Z_CODE', 'W_NAME', 'W_CODE',\n",
      "       'RK_NAME', 'RK_CODE', 'COUNT', 'T_NAME', 'T_CODE', 'KK_CODE', 'UK_NAME',\n",
      "       'UK_CODE', 'UK_ID', 'KK_NAME', 'GlobalID', 'Shape__Area',\n",
      "       'Shape__Length'],\n",
      "      dtype='object')\n",
      "NDVI CSV Kebele_ID 样例: ['ecba1d05-116b-4e2d-ba3f-5d4c516ba924', 'd37ccaf0-a552-4cfd-a6b8-6f993befac3c', '1021bd68-97ce-47dd-9b32-98ab9a912b06', 'e408d40e-19e4-4887-81ef-56403947d7f5', '2a879845-b5d4-47d5-8d00-e193da0011f8', 'ebe4424c-a1d9-499e-8b33-126c3825b507', '64db08e1-9609-43e3-8ebd-5b2759de130c', 'bb122ab0-6988-4eaa-8dd1-dd5f4bd2ff44', 'ad63ef57-d27d-4257-b79b-27a7d34657ef', '25696899-73ac-4515-878f-cc35a93a6182']\n",
      "GeoJSON GlobalID 样例: ['16bb4802-ed24-4cc0-a200-7c66e3dd54cc', '73a1a384-8026-4efa-8361-a55ec920de47', '485f9e8a-8919-4862-b9c1-e6ae1dd3ddbe', '67203873-adfd-421f-acfa-cca18ffce609', 'e286ed75-d290-465a-aca5-6925b5c4417b', '314edcc5-f1b2-498e-8410-e5c2ef95aebc', '5a57b5ea-1310-45ea-a814-8600596c0945', 'aa2f98e7-a5ff-453f-9e42-8e699f9a9128', '1158a12d-bcab-4566-9c0a-7cbe87ac0c53', 'c95b4677-bc9d-4fd4-8d06-36c5c24daf4d']\n",
      "GeoJSON KK_CODE 样例: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "GeoJSON W_CODE 样例: [10101, 10102, 10103, 10103, 10105, 10106, 10107, 10108, 10201, 10202]\n"
     ]
    }
   ],
   "source": [
    "# 检查 GeoJSON 可用的 ID 列\n",
    "print(\"GeoJSON columns:\", g_all.columns[:20])\n",
    "\n",
    "# 取一个子集出来看看前几行\n",
    "print(\"NDVI CSV Kebele_ID 样例:\", ndvi[\"Kebele_ID\"].head(10).tolist())\n",
    "\n",
    "# 尝试和 GeoJSON 里的 GlobalID 对比\n",
    "if \"GlobalID\" in g_all.columns:\n",
    "    print(\"GeoJSON GlobalID 样例:\", g_all[\"GlobalID\"].head(10).tolist())\n",
    "\n",
    "if \"KK_CODE\" in g_all.columns:\n",
    "    print(\"GeoJSON KK_CODE 样例:\", g_all[\"KK_CODE\"].head(10).tolist())\n",
    "\n",
    "if \"W_CODE\" in g_all.columns:\n",
    "    print(\"GeoJSON W_CODE 样例:\", g_all[\"W_CODE\"].head(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838d5da3-f793-4daa-bead-d504d1844b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
